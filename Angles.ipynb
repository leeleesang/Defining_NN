{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d35b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./DATASETS\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:04<00:00, 2393786.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./DATASETS\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./DATASETS\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./DATASETS\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 152490.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./DATASETS\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./DATASETS\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./DATASETS\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:02<00:00, 822191.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./DATASETS\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./DATASETS\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./DATASETS\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4676123.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./DATASETS\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./DATASETS\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification, Intrinsic dimension, Degeneracy\n",
    "%run SetUp.ipynb\n",
    "\n",
    "## Configuration \n",
    "Title = \"Angles\"\n",
    "device = \"cuda:1\"\n",
    "pt_option=True\n",
    "\n",
    "dataset = \"MNIST\"\n",
    "width = 2\n",
    "width_increment = 3\n",
    "selected_class = 0 ############### selected class #$##########\n",
    "# selected_class = int(input(\"Selected class:\")) ############### selected class #$##########\n",
    "dataset_type = \"Training set\" # \"Training + Test set\" // \"Training set\"\n",
    "data_balace = 1\n",
    "\n",
    "\n",
    "if dataset == \"MNIST\":\n",
    "    image_length = 28\n",
    "    image_channel=1\n",
    "    d = 28*28\n",
    "    n = 60000\n",
    "    data_balance = 1 ## the lambda value\n",
    "    Epochs = 30*1000\n",
    "    start_pruning = 9999 # pretraining\n",
    "\n",
    "elif dataset == \"FashionMNIST\":\n",
    "    image_length = 28\n",
    "    image_channel=1\n",
    "    d = 28*28\n",
    "    n = 60000\n",
    "    data_balance = 1 ## the lambda value\n",
    "    Epochs = 30*1000\n",
    "    start_pruning = 9999 # pretraining\n",
    "\n",
    "elif dataset == \"CIFAR10\":\n",
    "    image_length = 32\n",
    "    image_channel=3\n",
    "    d = 3*32*32\n",
    "    n = 50000\n",
    "    data_balance = 1 ## the lambda value\n",
    "    Epochs = 60*1000\n",
    "    start_pruning = 9999 # pretraining\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Wrong Dataset !\")\n",
    "    \n",
    "\n",
    "# n = 1000 # for debug, if need\n",
    "\n",
    "###############################\n",
    "num_classes = 0 # binary classification\n",
    "Goal_Accuracy = 99.99 \n",
    "first_positive_init = True  ## if False, this approximate the class : {selected_class}\n",
    "############################### if Ture, approximate the complement : {selected_class}^c\n",
    "\n",
    "\n",
    "# create directory\n",
    "output_path = f\"./Results/{Title}\"\n",
    "create_directory(output_path)\n",
    "# construct the dataset\n",
    "trn_X, trn_Y, test_X, test_Y = load_dataset(dataset, n)\n",
    "\n",
    "\n",
    "\n",
    "if dataset_type == \"Training + Test set\" : \n",
    "    ########### trn + test set #############\n",
    "    trn_X = torch.cat((trn_X, test_X)) ##### combine test set and trn set !\n",
    "    trn_Y = torch.cat((trn_Y, test_Y)) ##### \n",
    "    ########################################\n",
    "elif dataset_type == \"Training set\":\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f\"Wrong type for the dataset_type : {dataset_type}\")\n",
    "\n",
    "trn_Y = (trn_Y == selected_class).float()# change to binary class ## label 1 for the selected class.\n",
    "test_Y = (test_Y == selected_class).float()\n",
    "n = len(trn_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73283a95",
   "metadata": {},
   "source": [
    "Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10b1f20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Network setting # d -> d1 -> 1\n",
    "class polytope(nn.Module):\n",
    "    def __init__(self, width, output_class=1, positive_init=False, small_norm_init=False):\n",
    "        super(polytope, self).__init__()\n",
    "        self.fc0 = nn.Linear(d, width)\n",
    "        self.fc1 = nn.Linear(width, output_class, bias=False)\n",
    "        self.width = width # width\n",
    "        self.epoch = 0\n",
    "        self.data_balance = data_balance\n",
    "        self.bias = (1 - 2*positive_init)*5 # +-5\n",
    "        self.positive_init = positive_init\n",
    "        self.output_class = output_class\n",
    "        self.small_norm_init = small_norm_init\n",
    "        self.device = device\n",
    "        \n",
    "        # initialization\n",
    "        if small_norm_init: ## small norm init 은 일반적으로 안좋습니다. !\n",
    "            self.change_layer_weights(layer=0, W=0.001*torch.randn_like(self.W(0)), b=0.001*(self.b(0))) # multiply 0.01 \n",
    "            \n",
    "        if positive_init:\n",
    "            # if positivie init,  all v_k are positive.\n",
    "            self.fc1.weight = nn.Parameter(torch.sqrt((self.W(0).norm(dim=1)**2 + self.b(0)**2).view(1,-1)+1))\n",
    "        else:\n",
    "            # else, to all v_k are negative.\n",
    "            self.fc1.weight = nn.Parameter(-torch.sqrt((self.W(0).norm(dim=1)**2 + self.b(0)**2).view(1,-1)+1))\n",
    "        \n",
    "        # declare the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.g1 = self.fc0(x)\n",
    "        self.h1 = F.relu(self.g1)\n",
    "        self.g2 = self.fc1(self.h1) + self.bias\n",
    "        return self.g2.squeeze()\n",
    "    \n",
    "    def W(self, layer):\n",
    "        if layer ==0:\n",
    "            output = self.fc0.weight\n",
    "        elif layer ==1:\n",
    "            output = self.fc1.weight\n",
    "        return output.clone()\n",
    "    def b(self, layer):\n",
    "        if layer ==0:\n",
    "            output = self.fc0.bias\n",
    "        elif layer ==1:\n",
    "            output = self.fc1.bias\n",
    "        return output if output == None else output.clone()\n",
    "    \n",
    "    def activation_pattern(self, x):\n",
    "        self.forward(x)\n",
    "        return (self.h1>0).float()\n",
    "    \n",
    "    def change_layer_weights(self, layer, W, b):\n",
    "        if self.b(layer) == None : # no bias term\n",
    "            if W.shape == self.W(layer).shape and self.b(layer) == b:\n",
    "                if layer ==0:\n",
    "                    self.fc0.weight = nn.Parameter(W.to(self.device))\n",
    "                elif layer ==1:\n",
    "                    self.fc1.weight = nn.Parameter(W.to(self.device))\n",
    "            else:\n",
    "                raise ValueError(\"wrong shape of input tensors\")\n",
    "        else:\n",
    "            if W.shape == self.W(layer).shape and b.shape == self.b(layer).shape:\n",
    "                if layer ==0:\n",
    "                    self.fc0.weight = nn.Parameter(W.to(self.device))\n",
    "                    self.fc0.bias = nn.Parameter(b.to(self.device))\n",
    "                elif layer ==1:\n",
    "                    self.fc1.weight = nn.Parameter(W.to(self.device))\n",
    "    #                 self.fc1.bias = nn.Parameter(b)\n",
    "            else:\n",
    "                raise ValueError(\"wrong shape of input tensors\")\n",
    "    \n",
    "    \n",
    "    # Training\n",
    "    def train(self, repetition, trn_X_index):\n",
    "        self.fail = False\n",
    "        self.trn_loss_tr = np.empty(0)\n",
    "        self.test_loss_tr = np.empty(0)\n",
    "        self.trn_acc_tr = np.empty(0)\n",
    "        self.test_acc_tr = np.empty(0)\n",
    "\n",
    "        class0_outPoly_min = 1\n",
    "        test_acc = 0\n",
    "        test_loss = torch.zeros(1)\n",
    "        print(f\"=================================   Start Training. Repetition: {repetition+1}   ==================================\") if pt_option else None\n",
    "        time.sleep(1)\n",
    "\n",
    "        log_period = 500\n",
    "        for epoch in tqdm(range(Epochs)) :\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # since class may be imbalance\n",
    "            loss =  criterion(net(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(positive_init)).view(-1)]).squeeze(),\n",
    "                              trn_Y[trn_X_index][(trn_Y[trn_X_index]==float(positive_init)).view(-1)]) / len((trn_Y[trn_X_index]==float(positive_init)).view(-1))\n",
    "            loss += criterion(net(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(not positive_init)).view(-1)]).squeeze(), \n",
    "                              trn_Y[trn_X_index][(trn_Y[trn_X_index]==float(not positive_init)).view(-1)]) / len((trn_Y[trn_X_index]==float(not positive_init)).view(-1)) * self.data_balance\n",
    "            loss *= len((trn_Y[trn_X_index]).view(-1))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "#             self.pruning(trn_X[trn_X_index])\n",
    "\n",
    "\n",
    "            if epoch ==0 or epoch % log_period == (log_period-1) :\n",
    "                self.trn_loss_tr = np.append(self.trn_loss_tr, loss.item())\n",
    "                self.test_loss_tr = np.append(self.test_loss_tr, test_loss.item())\n",
    "\n",
    "                trn_acc = ((net(trn_X[trn_X_index])>0).float() == trn_Y[trn_X_index]).sum().item() / len(trn_X[trn_X_index]) *100\n",
    "                self.trn_acc_tr = np.append(self.trn_acc_tr, trn_acc)\n",
    "                self.test_acc_tr = np.append(self.test_acc_tr, test_acc)\n",
    "                class0_inPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]!=float(self.positive_init)).view(-1)]) == self.bias).sum().item()\n",
    "                class1_inPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(self.positive_init)).view(-1)]) == self.bias).sum().item()\n",
    "                class0_outPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]!=float(self.positive_init)).view(-1)]) != self.bias).sum().item()\n",
    "                class1_outPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(self.positive_init)).view(-1)]) != self.bias).sum().item()\n",
    "                writer.add_scalars(\"ReLU/Loss\", {\n",
    "                    \"Trn_Loss\": loss.item(),\n",
    "                    \"Test_Loss\": test_loss.item(), }\n",
    "                                   , epoch+1)\n",
    "                writer.add_scalars(\"ReLU/Accuracy\", {\n",
    "                    \"Trn_acc\": trn_acc,\n",
    "                    \"Test_acc\": test_acc, }\n",
    "                                   , epoch+1)\n",
    "                writer.add_scalars(\"ReLU/InOutClass\", {\n",
    "                    \"class0_inPoly\": class0_inPoly,\n",
    "                    \"class0_outPoly\": class0_outPoly,\n",
    "                    \"class0_inPoly\": class1_inPoly,\n",
    "                    \"class0_outPoly\": class1_outPoly,}\n",
    "                                   , epoch+1)\n",
    "                if pt_option :\n",
    "                    print(f\"Epoch: {epoch+1 :>5} | width: {self.width} | loss: {loss.item() :.4f} | ACC: {trn_acc:.3f}\", end=\"\")\n",
    "                    print(f\" | Wmin: {self.fc1.weight.abs().min():.1f} | class0_inPoly : {class0_inPoly}\", end=\"\")\n",
    "                    print(f\" | class0_outPoly : {class0_outPoly} | class1_inPoly : {class1_inPoly} | class1_outPoly : {class1_outPoly}\")\n",
    "                \n",
    "                if class0_outPoly == 0: # a good network. save.\n",
    "                    class0_outPoly_min = 0\n",
    "                    torch.save(self.state_dict(), folder_name+f\"/Rep{repetition+1}_saved_net_width_{width}_min.pt\") # save a good polytope\n",
    "                torch.save(self.state_dict(), folder_name+f\"/Rep{repetition+1}_saved_net_width_{width}.pt\") # save a good polytope\n",
    "                \n",
    "                if self.fc1.weight.sign().sum().abs() !=  self.width: # there is a flipped sign.\n",
    "                    print(\"!!! Sign flipped !!\") if pt_option else None\n",
    "                    self.fail = True # skip, train a new network for this round\n",
    "                    break\n",
    "                \n",
    "                if self.width == 0 : # there is no active neuron.\n",
    "                    print(\"!!! All neruons have been removed !!\") if pt_option else None\n",
    "                    self.fail = True # skip, train a new network for this round\n",
    "                    break\n",
    "\n",
    "                # terminating condition - if one class is completely surrounded by a convex polytope.\n",
    "                if (class0_outPoly == 0) and (class1_inPoly == 0):\n",
    "                    print(\"Found a complete convex polytope cover, escape the training loop\") if pt_option else None\n",
    "                    self.fail = False\n",
    "                    break\n",
    "                \n",
    "                TRN_ACC = (n - class0_outPoly - class1_inPoly) / n * 100\n",
    "                if (n - class0_outPoly - class1_inPoly) / n * 100 >= Goal_Accuracy :\n",
    "                    print(\"Found a 99.99% convex polytope cover, escape the training loop\") if pt_option else None\n",
    "                    self.fail = False\n",
    "                    break\n",
    "                \n",
    "                if ((epoch > 19000) and (epoch % 5000 == 4999)):\n",
    "                    _a = input(\"Keep Training? (y/n)\")\n",
    "                    while _a != 'y' and _a != 'n': \n",
    "                        print(\"Wrong input. Please enter again, only (y/n).\")\n",
    "                        _a = input(\"Keep Training? (y/n)\")\n",
    "                    if _a == 'n':\n",
    "                        break\n",
    "                        \n",
    "                \n",
    "                # Pruning and merging\n",
    "                self.pruning(trn_X[trn_X_index]) if epoch > start_pruning else None ## pruning after pre-training\n",
    "        \n",
    "        if class0_outPoly_min ==0:\n",
    "            self.load_state_dict(torch.load(folder_name+f\"/Rep{repetition+1}_saved_net_width_{width}_min.pt\")) # load the good polytope\n",
    "        \n",
    "        # if it fails to achieve convergence : \n",
    "        if (class0_outPoly > 10):\n",
    "            print(\"!!! It is failed to find a perfect polytope !!!!\") if pt_option else None\n",
    "            self.fail = True # skip, train a new network for this round\n",
    "#         else: # load the saved network with a good polytope\n",
    "#             self.load_state_dict(torch.load(folder_name+f\"/Rep{repetition+1}_saved_net_width_{width}.pt\")) # save a good polytope\n",
    "# #             self.eval()\n",
    "                                 \n",
    "        self.save_loss_graph()\n",
    "        self.save_result_txt()\n",
    "        self.save_visualization_weights()\n",
    "        time.sleep(1)\n",
    "        print(f\"===================================   Training finished, Repetition: {repetition+1}  ================================== \\n\\n\") if pt_option else None\n",
    "        return TRN_ACC\n",
    "        \n",
    "    \n",
    "    def save_visualization_weights(self):\n",
    "        # ### visualize and save the image of weight vectors ####\n",
    "        for _i in range(self.width):\n",
    "            if dataset != \"CIFAR10\":\n",
    "                plt.imshow(self.W(0)[_i].view(image_length,image_length).detach().cpu(), cmap='gray') # black and white image\n",
    "            else:\n",
    "                plt.imshow(self.W(0)[_i].view(image_channel,image_length,image_length).permute(1,2,0).clamp(0,1).detach().cpu()) # color image\n",
    "            plt.title(f\"{_i}-th weight\")\n",
    "            plt.savefig(folder_name+f\"/w{_i}.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    def save_loss_graph(self):\n",
    "        # plot and save the graphs\n",
    "        # PLOT THE LOSS GRAPH\n",
    "        plt.plot(self.trn_loss_tr, label=\"Train\")\n",
    "        plt.plot(self.test_loss_tr, label=\"Test\")\n",
    "        plt.xlabel(\"Iterations (k)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Rep{repetition+1}_Loss\")\n",
    "        plt.savefig(folder_name+\"/loss_fig_fullview.png\")\n",
    "#         plt.show() if pt_option else None\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT THE ACCURACY GRAPH\n",
    "        plt.plot(self.trn_acc_tr, label=\"Train\")\n",
    "        plt.plot(self.test_acc_tr, label=\"Test\")\n",
    "        plt.xlabel(\"Iterations (k)\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Rep{repetition+1}_Accuracy\")\n",
    "        plt.savefig(folder_name+\"/Accuracy.png\")\n",
    "#         plt.show() if pt_option else None\n",
    "        plt.close()\n",
    "    \n",
    "    # Save result txt file.\n",
    "    def save_result_txt(self):\n",
    "        class0_inPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]!=float(self.positive_init)).view(-1)]) == self.bias).sum().item()\n",
    "        class1_inPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(self.positive_init)).view(-1)]) == self.bias).sum().item()\n",
    "        class0_outPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]!=float(self.positive_init)).view(-1)]) != self.bias).sum().item()\n",
    "        class1_outPoly = (self.forward(trn_X[trn_X_index][(trn_Y[trn_X_index]==float(self.positive_init)).view(-1)]) != self.bias).sum().item()\n",
    "        \n",
    "        f = open(f\"./{folder_name}/Rep{repetition+1}_result.txt\", 'w')\n",
    "        f.write(\n",
    "        f\"\"\"\n",
    "            This is the CFG file.\n",
    "\n",
    "            # Accuracy\n",
    "            Trn_acc : {self.trn_acc_tr[-1] :.3f}\n",
    "            Test_acc : {self.test_acc_tr[-1] :.3f}\n",
    "\n",
    "            # Loss\n",
    "            Trn_loss : {self.trn_loss_tr[-1].item() :.4f} \n",
    "            Test_loss : {self.test_loss_tr[-1].item() :.4f} \n",
    "\n",
    "\n",
    "            # dataset\n",
    "            dataset = {dataset}\n",
    "            n = {n} # number of total data\n",
    "            d = {d} # dimension\n",
    "            num_class = {num_classes} # the class, used in this binary classification\n",
    "            starting_width = {width}\n",
    "            final_width = {self.width}\n",
    "            # Network\n",
    "            {net}\n",
    "            \n",
    "            # Polytope\n",
    "            number of data used in this training (Class 0 / 1): {class0_inPoly+class0_outPoly} / {class1_inPoly+class1_outPoly}\n",
    "            Class 0 in Polytope : {class0_inPoly}\n",
    "            Class 1 in Polytope : {class1_inPoly}\n",
    "            Class 0 out Polytope : {class0_outPoly}\n",
    "            Class 1 out Polytope : {class1_outPoly}\n",
    "            \n",
    "            # optimization\n",
    "            Epochs = {Epochs}\n",
    "            lr = {lr}\n",
    "            optimizer = {self.optimizer}\n",
    "            Last epoch = {self.epoch+1}\n",
    "            \n",
    "            ## trn_X_index\n",
    "            {trn_X_index}\n",
    "        \"\"\"\n",
    "        )\n",
    "        f.close()\n",
    "    \n",
    "    def pruning(self, dataset):\n",
    "        width_before = self.width\n",
    "        dataset_activation_pattern = self.activation_pattern(dataset).sum(dim=0)\n",
    "        if dataset_activation_pattern.max() == len(dataset) or dataset_activation_pattern.min() == 0 : \n",
    "            W0 = self.W(layer=0).detach()\n",
    "            b0 = self.b(layer=0).detach()\n",
    "            W1 = self.W(layer=1).detach()\n",
    "            activation_filter = ((self.activation_pattern(dataset).sum(dim=0) < len(dataset)).float()\n",
    "                                 * (self.activation_pattern(dataset).sum(dim=0) > 0).float()\n",
    "                                 * (self.W(layer=1).abs()>0.1).float().view(-1)\n",
    "                                )\n",
    "            # change polytope width \n",
    "            self.width = activation_filter.sum().long().item()\n",
    "            width_after = self.width\n",
    "            self.fc0 = nn.Linear(d, self.width)\n",
    "            self.fc1 = nn.Linear(self.width, self.output_class, bias=False)\n",
    "            self.change_layer_weights(layer=0, W=W0[(activation_filter == 1)], b=b0[activation_filter == 1])\n",
    "            self.change_layer_weights(layer=1, W=W1.view(-1)[activation_filter == 1].view(1,-1), b=None)\n",
    "            text = \"(removing)\"\n",
    "            print(f\"\\t{text:<15}The network is prunned, width : {width_before} --> {width_after}\") if pt_option else None\n",
    "            \n",
    "        ## merging vectors with same activation patterns ##\n",
    "        width_activation_pattern = self.activation_pattern(dataset) # len(dataset) x width\n",
    "        width_activation_pattern_unique = width_activation_pattern.unique(dim=1).t()\n",
    "        width_before = self.width\n",
    "        if len(width_activation_pattern_unique) < self.width :\n",
    "            self.width = len(width_activation_pattern_unique) \n",
    "            width_after = self.width\n",
    "            W0 = self.W(layer=0).detach()\n",
    "            b0 = self.b(layer=0).detach()\n",
    "            W1 = self.W(layer=1).detach()\n",
    "            self.fc0 = nn.Linear(d, self.width)\n",
    "            self.fc1 = nn.Linear(self.width, self.output_class, bias=False)\n",
    "            self.to(device)\n",
    "            # build weight matrices\n",
    "            new_W0 = self.W(layer=0).detach()\n",
    "            new_b0 = self.b(layer=0).detach()\n",
    "            new_W1 = self.W(layer=1).detach()\n",
    "            for index, pattern in enumerate(width_activation_pattern_unique):\n",
    "                new_W0[index] = W0[(width_activation_pattern.t() == pattern).prod(dim=1)==1].sum(dim=0)\n",
    "                new_b0[index] = b0[(width_activation_pattern.t() == pattern).prod(dim=1)==1].sum(dim=0)\n",
    "                new_W1[0][index] = W1[0][(width_activation_pattern.t() == pattern).prod(dim=1)==1].sum(dim=0)\n",
    "            self.change_layer_weights(layer=0, W=new_W0, b=new_b0)\n",
    "            self.change_layer_weights(layer=1, W=new_W1, b=None)\n",
    "            text = \"(merging)\"\n",
    "            print(f\"\\t{text:<15}The network is merged, width : {width_before} --> {width_after}\") if pt_option else None\n",
    "\n",
    "        ###### original #######\n",
    "        smallest_norm_neuron_index = self.width # not index yet.\n",
    "        smallest_norm = np.inf\n",
    "        width_activation_pattern = self.activation_pattern(dataset) # len(dataset) x width\n",
    "        for neuron_index in range(self.width): # for loop\n",
    "            activated_index = (width_activation_pattern[:, neuron_index] == 1)\n",
    "            # index 가 activated 된 data들의 activation pattern ## 이게 2 이상이면 제거해버리면 됨 !\n",
    "            if self.activation_pattern(dataset[activated_index]).sum(dim=1).min().item() >=2 :\n",
    "                # this neuron can be removed.\n",
    "                this_round_norm = (self.W(layer=0)[neuron_index].norm() * self.W(layer=1).squeeze()[neuron_index]).item() ## v||w||\n",
    "#                 this_round_norm = self.W(layer=1).squeeze()[neuron_index].item() ## v\n",
    "                if this_round_norm < smallest_norm:\n",
    "                    smallest_norm_neuron_index = neuron_index\n",
    "                    smallest_norm = this_round_norm\n",
    "        if smallest_norm_neuron_index < self.width:\n",
    "            # remove the small-norm redundant neuron, remove only one neuron at once\n",
    "            width_before = self.width\n",
    "            width_after = self.width - 1\n",
    "            W0 = self.W(layer=0).detach()\n",
    "            b0 = self.b(layer=0).detach()\n",
    "            W1 = self.W(layer=1).detach()\n",
    "            self.fc0 = nn.Linear(d, width_after)\n",
    "            self.fc1 = nn.Linear(width_after, self.output_class, bias=False)\n",
    "            self.to(device)        \n",
    "            new_W0 = torch.cat((W0[:smallest_norm_neuron_index], W0[smallest_norm_neuron_index+1:]), dim=0)\n",
    "            new_b0 = torch.cat((b0[:smallest_norm_neuron_index], b0[smallest_norm_neuron_index+1:]), dim=0)\n",
    "            new_W1 = torch.cat((W1[:,:smallest_norm_neuron_index], W1[:,smallest_norm_neuron_index+1:]), dim=1)\n",
    "            self.change_layer_weights(layer=0, W=new_W0, b=new_b0)\n",
    "            self.change_layer_weights(layer=1, W=new_W1, b=None)\n",
    "            self.width = width_after\n",
    "            text = \"(pruning)\"\n",
    "            print(f\"\\t{text:<15}In the polytope, a redundant neuron has been removed\") if pt_option else None\n",
    "        \n",
    "        \n",
    "        ### rescaling function ## here, we don't need to rescale the neuron.\n",
    "        rescale=1.1\n",
    "        intermediate_index = ( ( F.relu(self.forward(dataset)) != 0).float() * (self.forward(dataset) != self.bias).float() >0).squeeze()\n",
    "        if intermediate_index.float().sum() >0 :\n",
    "            activation_pattern_of_intermediate_data = self.activation_pattern(dataset[intermediate_index])\n",
    "            if activation_pattern_of_intermediate_data.max().item() >0 : ## max\n",
    "                new_W0 = self.W(layer=0).detach()\n",
    "                new_b0 = self.b(layer=0).detach()\n",
    "                new_W1 = self.W(layer=1).detach()\n",
    "                true_or_false = activation_pattern_of_intermediate_data.sum(dim=0)>0\n",
    "                for i, boolean in enumerate(true_or_false):\n",
    "                    if boolean:\n",
    "                        new_W0[i] = new_W0[i] * rescale\n",
    "                        new_b0[i] = new_b0[i] * rescale\n",
    "                        new_W1[0][i] = new_W1[0][i] * rescale\n",
    "                self.change_layer_weights(layer=0, W=new_W0, b=new_b0)\n",
    "                self.change_layer_weights(layer=1, W=new_W1, b=None)\n",
    "                text = \"(rescaling)\"\n",
    "                print(f\"\\t{text:<15}In the polytope, {true_or_false.sum().item()} neurons are rescaled by {rescale}\") if pt_option else None\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr) # net. paramgeter 를 optimizer 가능하도록 넣어줘야해...!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35353bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are finding polytope-basis cover of class [0]^c of MNIST, n=60000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "### Please enter the network width: ### 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================   Start Training. Repetition: 1   ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 1/30000 [00:00<4:03:34,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1 | width: 10 | loss: 4.8870 | ACC: 90.128 | Wmin: 1.0 | class0_inPoly : 0 | class0_outPoly : 54077 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                           | 512/30000 [00:04<04:10, 117.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   500 | width: 10 | loss: 0.1264 | ACC: 98.125 | Wmin: 1.0 | class0_inPoly : 27207 | class0_outPoly : 26870 | class1_inPoly : 4 | class1_outPoly : 5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                         | 1019/30000 [00:08<03:57, 122.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1000 | width: 10 | loss: 0.1072 | ACC: 98.318 | Wmin: 1.0 | class0_inPoly : 31517 | class0_outPoly : 22560 | class1_inPoly : 3 | class1_outPoly : 5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                        | 1513/30000 [00:12<03:58, 119.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1500 | width: 10 | loss: 0.0945 | ACC: 98.532 | Wmin: 1.0 | class0_inPoly : 33866 | class0_outPoly : 20211 | class1_inPoly : 2 | class1_outPoly : 5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████                                                                       | 2020/30000 [00:16<03:47, 122.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2000 | width: 10 | loss: 0.0860 | ACC: 98.660 | Wmin: 1.0 | class0_inPoly : 34727 | class0_outPoly : 19350 | class1_inPoly : 2 | class1_outPoly : 5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                     | 2514/30000 [00:20<03:49, 119.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2500 | width: 10 | loss: 0.0791 | ACC: 98.772 | Wmin: 1.0 | class0_inPoly : 34855 | class0_outPoly : 19222 | class1_inPoly : 2 | class1_outPoly : 5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                    | 3020/30000 [00:25<03:44, 120.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3000 | width: 10 | loss: 0.0716 | ACC: 98.890 | Wmin: 1.0 | class0_inPoly : 31696 | class0_outPoly : 22381 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▉                                                                   | 3514/30000 [00:29<03:42, 118.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3500 | width: 10 | loss: 0.0632 | ACC: 99.022 | Wmin: 1.1 | class0_inPoly : 29454 | class0_outPoly : 24623 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▏                                                                 | 4021/30000 [00:33<03:37, 119.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4000 | width: 10 | loss: 0.0558 | ACC: 99.150 | Wmin: 1.1 | class0_inPoly : 29202 | class0_outPoly : 24875 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▍                                                                | 4515/30000 [00:37<03:30, 121.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4500 | width: 10 | loss: 0.0494 | ACC: 99.258 | Wmin: 1.1 | class0_inPoly : 29420 | class0_outPoly : 24657 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▋                                                               | 5022/30000 [00:41<03:28, 119.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5000 | width: 10 | loss: 0.0436 | ACC: 99.382 | Wmin: 1.1 | class0_inPoly : 30644 | class0_outPoly : 23433 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▉                                                              | 5515/30000 [00:45<03:26, 118.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5500 | width: 10 | loss: 0.0385 | ACC: 99.490 | Wmin: 1.1 | class0_inPoly : 32080 | class0_outPoly : 21997 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▎                                                            | 6022/30000 [00:49<03:17, 121.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6000 | width: 10 | loss: 0.0344 | ACC: 99.575 | Wmin: 1.1 | class0_inPoly : 34131 | class0_outPoly : 19946 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▌                                                           | 6516/30000 [00:53<03:13, 121.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6500 | width: 10 | loss: 0.0309 | ACC: 99.623 | Wmin: 1.1 | class0_inPoly : 36112 | class0_outPoly : 17965 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▊                                                          | 7010/30000 [00:57<03:12, 119.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7000 | width: 10 | loss: 0.0275 | ACC: 99.688 | Wmin: 1.2 | class0_inPoly : 37860 | class0_outPoly : 16217 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                         | 7517/30000 [01:01<03:04, 121.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7500 | width: 10 | loss: 0.0245 | ACC: 99.747 | Wmin: 1.2 | class0_inPoly : 39574 | class0_outPoly : 14503 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▎                                                       | 8024/30000 [01:05<03:02, 120.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8000 | width: 10 | loss: 0.0220 | ACC: 99.792 | Wmin: 1.2 | class0_inPoly : 40971 | class0_outPoly : 13106 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▌                                                      | 8518/30000 [01:09<02:56, 121.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8500 | width: 10 | loss: 0.0198 | ACC: 99.827 | Wmin: 1.3 | class0_inPoly : 42184 | class0_outPoly : 11893 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 9022/30000 [01:13<03:01, 115.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9000 | width: 10 | loss: 0.0179 | ACC: 99.858 | Wmin: 1.3 | class0_inPoly : 43368 | class0_outPoly : 10709 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████                                                    | 9515/30000 [01:17<02:48, 121.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9500 | width: 10 | loss: 0.0162 | ACC: 99.888 | Wmin: 1.3 | class0_inPoly : 44297 | class0_outPoly : 9780 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████                                                  | 10022/30000 [01:21<02:46, 119.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 | width: 10 | loss: 0.0147 | ACC: 99.918 | Wmin: 1.4 | class0_inPoly : 45231 | class0_outPoly : 8846 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▏                                                | 10490/30000 [01:25<02:35, 125.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10500 | width: 10 | loss: 0.0133 | ACC: 99.940 | Wmin: 1.4 | class0_inPoly : 46140 | class0_outPoly : 7937 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▋                                                 | 10516/30000 [01:25<05:05, 63.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(rescaling)    In the polytope, 10 neurons are rescaled by 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████▍                                               | 10997/30000 [01:29<02:33, 123.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11000 | width: 10 | loss: 0.0105 | ACC: 99.983 | Wmin: 1.6 | class0_inPoly : 48749 | class0_outPoly : 5328 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████▉                                                | 11023/30000 [01:30<04:13, 74.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(rescaling)    In the polytope, 10 neurons are rescaled by 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▋                                              | 11491/30000 [01:34<02:34, 119.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11500 | width: 10 | loss: 0.0088 | ACC: 100.000 | Wmin: 1.8 | class0_inPoly : 50702 | class0_outPoly : 3375 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▏                                              | 11516/30000 [01:34<04:13, 72.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(rescaling)    In the polytope, 10 neurons are rescaled by 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▉                                             | 11997/30000 [01:38<02:24, 124.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12000 | width: 10 | loss: 0.0078 | ACC: 100.000 | Wmin: 2.0 | class0_inPoly : 51843 | class0_outPoly : 2234 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 12023/30000 [01:39<04:01, 74.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(rescaling)    In the polytope, 10 neurons are rescaled by 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████▏                                           | 12491/30000 [01:42<02:21, 124.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12500 | width: 10 | loss: 0.0072 | ACC: 100.000 | Wmin: 2.3 | class0_inPoly : 52670 | class0_outPoly : 1407 | class1_inPoly : 0 | class1_outPoly : 5923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████▏                                           | 12499/30000 [01:43<02:24, 120.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m trn_X_index_this_time[(trn_Y\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mfloat\u001b[39m(positive_init))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m#### consider all data points in the other class\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m trn_acc \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepetition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_X_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrn_X_index_this_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m again \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Do you wanna train again? (y/n) ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m again \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m again \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m: \n",
      "Cell \u001b[1;32mIn[2], line 171\u001b[0m, in \u001b[0;36mpolytope.train\u001b[1;34m(self, repetition, trn_X_index)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;66;03m# Pruning and merging\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrn_X_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m start_pruning \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m## pruning after pre-training\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class0_outPoly_min \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(folder_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Rep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepetition\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_saved_net_width_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_min.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m# load the good polytope\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 301\u001b[0m, in \u001b[0;36mpolytope.pruning\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m## merging vectors with same activation patterns ##\u001b[39;00m\n\u001b[0;32m    300\u001b[0m width_activation_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_pattern(dataset) \u001b[38;5;66;03m# len(dataset) x width\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m width_activation_pattern_unique \u001b[38;5;241m=\u001b[39m \u001b[43mwidth_activation_pattern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mt()\n\u001b[0;32m    302\u001b[0m width_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(width_activation_pattern_unique) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth :\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:938\u001b[0m, in \u001b[0;36mTensor.unique\u001b[1;34m(self, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    930\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39munique,\n\u001b[0;32m    931\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    936\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m    937\u001b[0m     )\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\functional.py:996\u001b[0m, in \u001b[0;36m_return_output\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[1;32m--> 996\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\functional.py:902\u001b[0m, in \u001b[0;36m_unique_impl\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    898\u001b[0m         unique, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msorted\u001b[39m, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse,\n\u001b[0;32m    899\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts, dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_dim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    910\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_unique2(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msorted\u001b[39m,\n\u001b[0;32m    913\u001b[0m         return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse,\n\u001b[0;32m    914\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[0;32m    915\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimization setting\n",
    "lr = 0.0001\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# finding the polytope cover !\n",
    "repetition = 0\n",
    "trn_X_index_all = (torch.ones(len(trn_X))>0).to(device) # Boolean tensor, shape = len(dataset)\n",
    "trn_X_index = trn_X_index_all.clone()\n",
    "network_list = []\n",
    "folder_name_above = output_path + f'/runs/{dataset}/' + datetime.datetime.now().strftime(\"%B%d_%H_%M_%S\")\n",
    "create_directory(folder_name_above) # create output folder\n",
    "\n",
    "\n",
    "complement = \"^c\" if first_positive_init else \"\"\n",
    "print(f\"We are finding polytope-basis cover of class [{selected_class}]\"+complement+f\" of {dataset}, n={n}\")\n",
    "positive_init = first_positive_init\n",
    "# while trn_X_index[(trn_Y==0).view(-1)].sum()>0 and trn_X_index[(trn_Y==1).view(-1)].sum()>0 : # 100% accuracy\n",
    "# while trn_X_index[(trn_Y==0).view(-1)].sum()>0 and trn_X_index[(trn_Y==1).view(-1)].sum()>0 : # 원래 쓰던거\n",
    "trn_acc = 0\n",
    "while trn_acc < Goal_Accuracy : ## only for single polytope cover !!\n",
    "    width = int(input(\"### Please enter the network width: ###\")) ## manually adjust the width\n",
    "    net = polytope(width=width, positive_init=positive_init, small_norm_init=True).to(device)\n",
    "    folder_name = folder_name_above + f\"/Cover_{repetition+1}\"\n",
    "    writer = SummaryWriter(folder_name)\n",
    "    \n",
    "    # training\n",
    "    trn_X_index_this_time = trn_X_index.clone()\n",
    "    ####\n",
    "    trn_X_index_this_time[(trn_Y==float(positive_init)).view(-1)] = True  #### consider all data points in the other class\n",
    "    ####\n",
    "    trn_acc = net.train(repetition=repetition, trn_X_index= trn_X_index_this_time)\n",
    "    again = input(\"### Do you wanna train again? (y/n) ###\")\n",
    "    while again != 'y' and again != 'n': \n",
    "        print(\"Wrong input. Please enter again, only (y/n).\")\n",
    "        again = input(\"### Do you wanna train again? (y/n) ###\")\n",
    "    if again == 'y':\n",
    "        net.fail = True\n",
    "    if net.fail:\n",
    "        # there is some problem for finding a cover in this training time.\n",
    "        # therefore, we skip this try and re-train.\n",
    "#         positive_init = not positive_init # flip the convexity of the class.\n",
    "        continue ## CAUTION : this might occur infinite loop\n",
    "    \n",
    "    # otherwise, it was successful.\n",
    "    # after trainnig, extract the index.\n",
    "    trn_X_index_in_polytope = ((net(trn_X).view(-1) * trn_X_index)  == net.bias) # boolean tensor, shape = len(dataset)\n",
    "    # new index\n",
    "    trn_X_index = trn_X_index * trn_X_index_in_polytope\n",
    "        \n",
    "    network_list.append(net) # add to the network_list\n",
    "    positive_init = not positive_init # flip the convexity of the class.\n",
    "    repetition += 1\n",
    "\n",
    "# result\n",
    "if pt_option :\n",
    "    print(\"Completed to find a polytope-basis cover.\")\n",
    "    print(f\"There are {len(network_list)} polytopes.\") \n",
    "    print(network_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac72c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Result ####\n",
    "width_list = [net.width for net in network_list]\n",
    "print(f\"Output: a polytope-basis cover of class [{selected_class}]{complement}\")\n",
    "print(f\"There are totally {len(network_list)} polytopes. The widths are\",width_list,end=\"\\n\\n\")\n",
    "\n",
    "#### Accuracy #########\n",
    "# trn acc\n",
    "previous_trn_answer = torch.zeros_like(trn_Y)\n",
    "for j, net in enumerate(network_list):\n",
    "    previous_trn_answer += (-1)**j * (net(trn_X) == net.bias).float()\n",
    "correct_trn_data = ((previous_trn_answer>0).float() == float(first_positive_init) + (1-2*(float(first_positive_init)))*trn_Y).sum().item()\n",
    "trn_acc =  correct_trn_data / len(trn_Y) * 100\n",
    "print(f\"Trn ACC : {trn_acc:.2f} %  ||  # incorrect data : {len(trn_Y) - correct_trn_data} / {len(trn_Y)}\")\n",
    "\n",
    "# test ACC\n",
    "previous_test_answer = torch.zeros_like(test_Y)\n",
    "for j, net in enumerate(network_list):\n",
    "    previous_test_answer += (-1)**j * (net(test_X) == net.bias).float()\n",
    "correct_test_data = ((previous_test_answer>0).float() == float(first_positive_init) + (1-2*(float(first_positive_init)))*test_Y).sum().item()\n",
    "test_acc =  correct_test_data / len(test_Y) * 100\n",
    "print(f\"Test ACC : {test_acc:.2f} %  ||  # incorrect data : {len(test_Y) - correct_test_data} / {len(test_Y)}\")\n",
    "\n",
    "f = open(f\"./{folder_name_above}/Total_result.txt\", 'w')\n",
    "f.write(\n",
    "f\"\"\"\n",
    "    This is the result file\n",
    "    \n",
    "    # dataset\n",
    "    dataset = {dataset}, {dataset_type}\n",
    "    n = {len(trn_X)} # number of trained data\n",
    "    d = {d} # dimension\n",
    "    Initialization width = {width}\n",
    "    \n",
    "    # class, convexity\n",
    "    selected_class = {selected_class} # the class, used in this binary classification\n",
    "    positive_init = {first_positive_init}\n",
    "    Therefore, it finds a polytope-basis cover of class [{selected_class}]{complement})\n",
    "    data_balance = {data_balance}\n",
    "    \n",
    "    # Accuracy\n",
    "    Trn ACC : {trn_acc:.2f} %  ||  # incorrect data : {len(trn_Y) - correct_trn_data} / {len(trn_Y)}\n",
    "    Test ACC : {test_acc:.2f} %  ||  # incorrect data : {len(test_Y) - correct_test_data} / {len(test_Y)}\n",
    "    \n",
    "    # optimization\n",
    "    Epochs = {Epochs}\n",
    "    Start_pruning = {start_pruning}\n",
    "    \n",
    "    There are totally {len(network_list)} polytopes. The widths are\n",
    "    {width_list}\n",
    "    \n",
    "    The end.\n",
    "\"\"\"\n",
    ")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac167a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACC\n",
    "previous_trn_answer = torch.zeros_like(trn_Y)\n",
    "for j, net in enumerate(network_list):\n",
    "    previous_trn_answer += (-1)**j * (net(trn_X) == net.bias).float()\n",
    "correct_trn_data = ((previous_trn_answer>0).float() == float(first_positive_init) + (1-2*(float(first_positive_init)))*trn_Y).sum().item()\n",
    "trn_acc =  correct_trn_data / len(trn_Y) * 100\n",
    "print(f\"Trn ACC : {trn_acc:.2f} %  ||  # incorrect data : {len(trn_Y) - correct_trn_data} / {len(trn_Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a9f1d",
   "metadata": {},
   "source": [
    "### Row-interchange, Column-interchange, useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow(A<.9)\n",
    "# imshow(A)\n",
    "\n",
    "#### change row ####\n",
    "def change_row(A, i, j):\n",
    "    A[[i, j]] = A[[j, i]]\n",
    "    return A\n",
    "### change column ####\n",
    "def change_column(A, i, j):\n",
    "    B = A.t()\n",
    "    B[[i, j]] = B[[j, i]]\n",
    "    return B.t()\n",
    "\n",
    "### rearrangement to be diagonal\n",
    "def rearrangement(A):\n",
    "    assert A.dim() == 2\n",
    "    assert A.size(0) == A.size(1)\n",
    "    B = A.clone()\n",
    "    m = B.size(0)\n",
    "    horizontal_index = torch.arange(m).view(-1,1)\n",
    "    vertical_index = torch.arange(m).view(1,-1)\n",
    "    \n",
    "    for i in range(m):\n",
    "        # i 번째 row 에서 정렬.\n",
    "        j = B[i].argmin().item()\n",
    "        B = change_column(B, i, j) ;     vertical_index = change_column(vertical_index, i, j)\n",
    "        \n",
    "    # rearrange, w.r.t. diagonal entries\n",
    "    C = B.clone()\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        for i,j in enumerate(B.diag().topk(m, largest=False)[1]):\n",
    "            j = j.item()\n",
    "            if i != j :\n",
    "                B = change_column(B,i,j) ;    vertical_index = change_column(vertical_index, i, j)\n",
    "                B = change_row(B,i,j) ;       horizontal_index = change_row(horizontal_index, i, j)\n",
    "                break\n",
    "            if i == j and j == (m-1):\n",
    "                stop = True\n",
    "    return B, horizontal_index, vertical_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f7dd7-e017-4979-83a3-d18dfcd5badb",
   "metadata": {},
   "source": [
    "### Load two saved polytope covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35550278",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis - unique solution ?\n",
    "selected_class = 0\n",
    "width = 4\n",
    "net1 = polytope(width=width, positive_init=positive_init).to(device)\n",
    "net1.load_state_dict(torch.load(f\"./Results/Rebuttal/runs/{dataset}_saved/m_{selected_class}_{width}/Cover_1/Rep1_saved_net_width_{width}.pt\"))\n",
    "W1 = net1.W(0)\n",
    "\n",
    "net2 = polytope(width=width, positive_init=positive_init).to(device)\n",
    "net2.load_state_dict(torch.load(f\"./Results/Rebuttal/runs/{dataset}_saved/m_{selected_class}_{width}/Cover_1/Rep1_saved_net_width_{width}.pt\"))\n",
    "W2 = net2.W(0)\n",
    "\n",
    "\n",
    "A = torch.zeros(width, width)\n",
    "for a in range(width):\n",
    "    for b in range(width):\n",
    "        A[a][b] = (protractor(W1[a],W2[b]).item())\n",
    "# print(A)\n",
    "B, horizontal_index, vertical_index = rearrangement(A) ### rearrangement \n",
    "# print(\"Arranged\")\n",
    "W1 = W1[horizontal_index.view(-1)] ### rearrangement \n",
    "W2 = W2[vertical_index.view(-1)] ### rearrangement \n",
    "for a in range(width):\n",
    "    for b in range(width):\n",
    "        A[a][b] = (protractor(W1[a],W2[b]).item())\n",
    "fig, axs = plt.subplots(2,width, figsize=(2*width*3,width*3))\n",
    "for i in range(width):\n",
    "    axs[0][i].imshow(W1[i].view(28,28).detach().cpu(), cmap='gray')\n",
    "#     axs[0][i].set_title(f\"w{i+1}\")\n",
    "    axs[1][i].imshow(W2[i].view(28,28).detach().cpu(), cmap='gray')\n",
    "    axs[0][i].axis(\"off\")\n",
    "    axs[1][i].axis(\"off\")\n",
    "plt.savefig(folder_name_above+f\"/image_class{selected_class}.png\")\n",
    "plt.show()\n",
    "\n",
    "print(A)\n",
    "fig = plt.figure(figsize = (2*width,2*width))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(A, cmap='gray')\n",
    "xticks_label = []\n",
    "yticks_label = []\n",
    "for i in range(width):\n",
    "    xticks_label.append(r\"$\\tilde{w}$\"+fr\"$_{i+1}$\")\n",
    "    yticks_label.append(fr\"$w_{i+1}$\")\n",
    "    for j in range(width):\n",
    "        ax.text(i,j,f\"{A[j][i].item(): .4f}\", color='red', ha='center', va='center', fontsize=20)\n",
    "fig.suptitle(r\"Angle bewteen $w_i$ and $\\tilde{w}_j$\", fontsize=20)\n",
    "plt.xticks(np.arange(width))\n",
    "plt.yticks(np.arange(width))\n",
    "ax.set_xticklabels(xticks_label, fontsize=20)\n",
    "ax.set_yticklabels(yticks_label, fontsize=20)\n",
    "plt.savefig(folder_name_above+f\"/Angle_color_class{selected_class}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
