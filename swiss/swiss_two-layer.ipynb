{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1057d80-5d21-4882-aa51-2e359f2d3957",
   "metadata": {},
   "source": [
    "### This file trains a convex two-layer ReLU network on the swiss roll dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification, Intrinsic dimension, Degeneracy\n",
    "%run swiss_SetUp.ipynb\n",
    "\n",
    "## Configuration\n",
    "Title = \"SWISS\" # general two layer\n",
    "device = \"cuda:0\"\n",
    "pt_option=True\n",
    "width = 30\n",
    "dataset = \"Swiss\"\n",
    "d = 2\n",
    "n = 1000 # used number of data\n",
    "num_class = 9\n",
    "\n",
    "# create directory\n",
    "output_path = f\"./Results/{Title}\"\n",
    "create_directory(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "DATA = make_swiss_roll(n_samples=int(n/2), noise=0.4)[0]\n",
    "\n",
    "trn_X = torch.tensor(DATA)[:,0].to(device)\n",
    "trn_X = torch.stack((trn_X, torch.tensor(DATA)[:,2].to(device)), dim=1)\n",
    "trn_X = torch.cat((trn_X, -trn_X), dim=0).float()\n",
    "trn_Y = torch.ones(int(n/2)).to(device)\n",
    "trn_Y = torch.cat((trn_Y, 0*trn_Y), dim=0).float().view(-1,1)\n",
    "test_X = trn_X\n",
    "test_Y = trn_Y\n",
    "trn_X = trn_X * 0.1\n",
    "data = trn_X\n",
    "id = int(n/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expected-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network setting # d -> d1 -> 1\n",
    "class polytope(nn.Module):\n",
    "    def __init__(self, width, output_class=1, positive_init=True):\n",
    "        super(polytope, self).__init__()\n",
    "        self.fc0 = nn.Linear(d, width)\n",
    "        self.fc1 = nn.Linear(width, output_class, bias=False)\n",
    "        self.width = width # width\n",
    "        self.bias = 1 - positive_init * 2\n",
    "        if positive_init:\n",
    "            # initialization, to all v_k to be positive.\n",
    "            self.fc1.weight = nn.Parameter((self.W(0).norm(dim=1)**2 + self.b(0)**2).view(1,-1)+1)\n",
    "        else:\n",
    "               # initialization, to all v_k to be negative.\n",
    "            self.fc1.weight = nn.Parameter(-(self.W(0).norm(dim=1)**2 + self.b(0)**2).view(1,-1)-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.g1 = self.fc0(x)\n",
    "        self.h1 = F.relu(self.g1)\n",
    "        self.g2 = self.fc1(self.h1)\n",
    "        return self.g2 + self.bias\n",
    "    \n",
    "    def W(self, i):\n",
    "        if i ==0:\n",
    "            output = self.fc0.weight\n",
    "        elif i ==1:\n",
    "            output = self.fc1.weight\n",
    "        return output\n",
    "    def b(self, i):\n",
    "        if i ==0:\n",
    "            output = self.fc0.bias\n",
    "        elif i ==1:\n",
    "            output = self.fc1.bias\n",
    "        return output\n",
    "    \n",
    "    def activation_pattern(self, x):\n",
    "        self.forward(x)\n",
    "        return (self.h1>0).float()\n",
    "    \n",
    "    def change_layer_weights(self, i, W, b):\n",
    "        if W.shape == self.W(i).shape and b.shape == self.b(i).shape:\n",
    "            if i ==0:\n",
    "                self.fc0.weight = nn.Parameter(W)\n",
    "                self.fc0.bias = nn.Parameter(b)\n",
    "            elif i ==1:\n",
    "                self.fc1.weight = nn.Parameter(W)\n",
    "                self.fc1.bias = nn.Parameter(b)\n",
    "        else:\n",
    "            raise ValueError(\"wrong shape of input tensors\")\n",
    "    \n",
    "    def partition(self, th=0.001, w=1.6, title=\"img\", color='blue', partition=True):\n",
    "        N = 200\n",
    "        x,y = torch.meshgrid(torch.linspace(-w,w,N), torch.linspace(-w,w,N))\n",
    "        grid = torch.stack((x,y),dim=2).to(device).float() # SHAPE 10,10,2\n",
    "        rank = (self.forward(grid.view(-1,2))>th).float().view(N,N)                     # decision boundary, output<0\n",
    "        plt.contourf(x,y,rank.cpu(), np.arange(-1,2,1), cmap='gray')\n",
    "        plt.colorbar()\n",
    "        if partition:\n",
    "            for i in range(self.width):\n",
    "                plt.contour(x,y, self.activation_pattern(grid.view(-1,2)).float().cpu().view(N,N,-1)[:,:,i], levels=1, colors=color, linewidths=0.5)\n",
    "\n",
    "        blue_patch = mpatches.Patch(color='blue', label='1st layer')\n",
    "        plt.legend(handles=[blue_patch])\n",
    "        # dataset\n",
    "        plt.scatter(trn_X[:id,0].cpu(),trn_X[:id,1].cpu(), marker='.')\n",
    "        plt.scatter(trn_X[id:,0].cpu(),trn_X[id:,1].cpu(), marker='.')\n",
    "        plt.title(\"Activation and decision boundary\")\n",
    "        # save the figure\n",
    "        plt.savefig(f'./figs/{title}.png')\n",
    "#         plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "registered-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=polytope(width=10).to(device)\n",
    "net.partition(title=\"0\") # save the initialization state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-drill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Epoch:     1 || TRN_loss: 2.3765 || TRN_ACC: 50.000 || trn_blue_acc: 100.00 || trn_oragne_acc = 0.00\n",
      "Epoch:  1000 || TRN_loss: 1.5983 || TRN_ACC: 50.000 || trn_blue_acc: 100.00 || trn_oragne_acc = 0.00\n",
      "Epoch:  2000 || TRN_loss: 1.1296 || TRN_ACC: 50.000 || trn_blue_acc: 100.00 || trn_oragne_acc = 0.00\n",
      "Epoch:  3000 || TRN_loss: 0.8536 || TRN_ACC: 49.200 || trn_blue_acc: 97.80 || trn_oragne_acc = 0.60\n",
      "Epoch:  4000 || TRN_loss: 0.7095 || TRN_ACC: 58.500 || trn_blue_acc: 86.40 || trn_oragne_acc = 30.60\n",
      "Epoch:  5000 || TRN_loss: 0.6500 || TRN_ACC: 63.800 || trn_blue_acc: 74.80 || trn_oragne_acc = 52.80\n",
      "Epoch:  6000 || TRN_loss: 0.6311 || TRN_ACC: 65.500 || trn_blue_acc: 69.40 || trn_oragne_acc = 61.60\n",
      "Epoch:  7000 || TRN_loss: 0.6332 || TRN_ACC: 65.800 || trn_blue_acc: 65.80 || trn_oragne_acc = 65.80\n",
      "Epoch:  8000 || TRN_loss: 0.6335 || TRN_ACC: 66.900 || trn_blue_acc: 63.20 || trn_oragne_acc = 70.60\n",
      "Epoch:  9000 || TRN_loss: 0.6243 || TRN_ACC: 66.600 || trn_blue_acc: 62.00 || trn_oragne_acc = 71.20\n",
      "Epoch: 10000 || TRN_loss: 0.6220 || TRN_ACC: 66.500 || trn_blue_acc: 61.40 || trn_oragne_acc = 71.60\n",
      "Epoch: 11000 || TRN_loss: 0.6207 || TRN_ACC: 66.300 || trn_blue_acc: 61.60 || trn_oragne_acc = 71.00\n",
      "Epoch: 12000 || TRN_loss: 0.6174 || TRN_ACC: 65.900 || trn_blue_acc: 61.60 || trn_oragne_acc = 70.20\n",
      "Epoch: 13000 || TRN_loss: 0.6174 || TRN_ACC: 66.300 || trn_blue_acc: 62.40 || trn_oragne_acc = 70.20\n",
      "Epoch: 14000 || TRN_loss: 0.6163 || TRN_ACC: 66.400 || trn_blue_acc: 62.60 || trn_oragne_acc = 70.20\n",
      "Epoch: 15000 || TRN_loss: 0.6131 || TRN_ACC: 66.600 || trn_blue_acc: 62.60 || trn_oragne_acc = 70.60\n",
      "Epoch: 16000 || TRN_loss: 0.6119 || TRN_ACC: 66.600 || trn_blue_acc: 62.60 || trn_oragne_acc = 70.60\n",
      "Epoch: 17000 || TRN_loss: 0.6102 || TRN_ACC: 66.800 || trn_blue_acc: 62.60 || trn_oragne_acc = 71.00\n",
      "Epoch: 18000 || TRN_loss: 0.6089 || TRN_ACC: 66.700 || trn_blue_acc: 62.40 || trn_oragne_acc = 71.00\n",
      "Epoch: 19000 || TRN_loss: 0.6070 || TRN_ACC: 66.700 || trn_blue_acc: 62.40 || trn_oragne_acc = 71.00\n",
      "Epoch: 20000 || TRN_loss: 0.6058 || TRN_ACC: 67.000 || trn_blue_acc: 62.40 || trn_oragne_acc = 71.60\n",
      "Epoch: 21000 || TRN_loss: 0.6040 || TRN_ACC: 66.800 || trn_blue_acc: 62.00 || trn_oragne_acc = 71.60\n",
      "Epoch: 22000 || TRN_loss: 0.6026 || TRN_ACC: 66.800 || trn_blue_acc: 61.80 || trn_oragne_acc = 71.80\n",
      "Epoch: 23000 || TRN_loss: 0.6009 || TRN_ACC: 66.800 || trn_blue_acc: 61.20 || trn_oragne_acc = 72.40\n",
      "Epoch: 24000 || TRN_loss: 0.6003 || TRN_ACC: 66.800 || trn_blue_acc: 61.20 || trn_oragne_acc = 72.40\n",
      "Epoch: 25000 || TRN_loss: 0.5990 || TRN_ACC: 66.800 || trn_blue_acc: 61.20 || trn_oragne_acc = 72.40\n",
      "Epoch: 26000 || TRN_loss: 0.5981 || TRN_ACC: 66.900 || trn_blue_acc: 61.00 || trn_oragne_acc = 72.80\n",
      "Epoch: 27000 || TRN_loss: 0.5966 || TRN_ACC: 66.800 || trn_blue_acc: 60.80 || trn_oragne_acc = 72.80\n",
      "Epoch: 28000 || TRN_loss: 0.5951 || TRN_ACC: 66.600 || trn_blue_acc: 60.40 || trn_oragne_acc = 72.80\n",
      "Epoch: 29000 || TRN_loss: 0.5944 || TRN_ACC: 66.600 || trn_blue_acc: 60.20 || trn_oragne_acc = 73.00\n",
      "Epoch: 30000 || TRN_loss: 0.5937 || TRN_ACC: 66.400 || trn_blue_acc: 59.60 || trn_oragne_acc = 73.20\n",
      "Epoch: 31000 || TRN_loss: 0.5930 || TRN_ACC: 66.300 || trn_blue_acc: 59.40 || trn_oragne_acc = 73.20\n",
      "Epoch: 32000 || TRN_loss: 0.5924 || TRN_ACC: 66.100 || trn_blue_acc: 59.00 || trn_oragne_acc = 73.20\n",
      "Epoch: 33000 || TRN_loss: 0.5915 || TRN_ACC: 66.000 || trn_blue_acc: 58.60 || trn_oragne_acc = 73.40\n",
      "Epoch: 34000 || TRN_loss: 0.5909 || TRN_ACC: 66.000 || trn_blue_acc: 58.20 || trn_oragne_acc = 73.80\n",
      "Epoch: 35000 || TRN_loss: 0.5904 || TRN_ACC: 66.100 || trn_blue_acc: 58.20 || trn_oragne_acc = 74.00\n",
      "Epoch: 36000 || TRN_loss: 0.5903 || TRN_ACC: 66.000 || trn_blue_acc: 58.00 || trn_oragne_acc = 74.00\n",
      "Epoch: 37000 || TRN_loss: 0.5892 || TRN_ACC: 65.900 || trn_blue_acc: 57.80 || trn_oragne_acc = 74.00\n",
      "Epoch: 38000 || TRN_loss: 0.5888 || TRN_ACC: 66.000 || trn_blue_acc: 57.80 || trn_oragne_acc = 74.20\n",
      "Epoch: 39000 || TRN_loss: 0.5888 || TRN_ACC: 66.000 || trn_blue_acc: 57.60 || trn_oragne_acc = 74.40\n",
      "Epoch: 40000 || TRN_loss: 0.5881 || TRN_ACC: 65.700 || trn_blue_acc: 57.00 || trn_oragne_acc = 74.40\n",
      "Epoch: 41000 || TRN_loss: 0.5881 || TRN_ACC: 65.700 || trn_blue_acc: 57.00 || trn_oragne_acc = 74.40\n",
      "Epoch: 42000 || TRN_loss: 0.5874 || TRN_ACC: 65.900 || trn_blue_acc: 57.00 || trn_oragne_acc = 74.80\n",
      "Epoch: 43000 || TRN_loss: 0.5872 || TRN_ACC: 65.800 || trn_blue_acc: 56.80 || trn_oragne_acc = 74.80\n",
      "Epoch: 44000 || TRN_loss: 0.5869 || TRN_ACC: 65.500 || trn_blue_acc: 56.20 || trn_oragne_acc = 74.80\n",
      "Epoch: 45000 || TRN_loss: 0.5863 || TRN_ACC: 65.500 || trn_blue_acc: 56.00 || trn_oragne_acc = 75.00\n",
      "Epoch: 46000 || TRN_loss: 0.5861 || TRN_ACC: 65.600 || trn_blue_acc: 55.80 || trn_oragne_acc = 75.40\n",
      "Epoch: 47000 || TRN_loss: 0.5859 || TRN_ACC: 65.500 || trn_blue_acc: 55.60 || trn_oragne_acc = 75.40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m log_period \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Epochs) :\n\u001b[1;32m---> 29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_X\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_X\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:731\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3226\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m   3224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.0001\n",
    "Epochs=100*1000\n",
    "    \n",
    "folder_name = output_path + '/runs/' + datetime.datetime.now().strftime(\"%B%d_%H_%M_%S\")\n",
    "writer = SummaryWriter(folder_name)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "grad_norm = 0\n",
    "trn_loss_tr = np.empty(0)\n",
    "test_loss_tr = np.empty(0)\n",
    "trn_acc_tr = np.empty(0)\n",
    "test_acc_tr = np.empty(0)\n",
    "\n",
    "\n",
    "test_acc = 0\n",
    "test_loss = torch.zeros(1)\n",
    "print(\"Start Training\")\n",
    "time.sleep(1)\n",
    "\n",
    "log_period = 1000\n",
    "for epoch in range(Epochs) :\n",
    "    loss = criterion(net(trn_X)*(net(trn_X)>-0.9).float(), trn_Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    if epoch ==0 or epoch % 1000 == 999 : # perturb every 50000 steps\n",
    "        trn_loss_tr = np.append(trn_loss_tr, loss.item())\n",
    "        test_loss_tr = np.append(test_loss_tr, test_loss.item())\n",
    "        \n",
    "        trn_blue_acc = (net(trn_X[:500])>0).float().sum().item() / 5\n",
    "        trn_orange_acc = (net(trn_X[500:])<0).float().sum().item() / 5\n",
    "        \n",
    "        trn_acc = ((net(trn_X)>0).float() == trn_Y).sum().item() / len(trn_Y) *100\n",
    "        trn_acc_tr = np.append(trn_acc_tr, trn_acc)\n",
    "        test_acc_tr = np.append(test_acc_tr, test_acc)\n",
    "        writer.add_scalars(\"ReLU/Accuracy\", {\n",
    "            \"Trn_acc\": trn_acc,\n",
    "            \"Test_acc\": test_acc, }\n",
    "                        , epoch+1)\n",
    "        if pt_option :\n",
    "            print(f\"Epoch: {epoch+1 :>5} || TRN_loss: {loss.item() :.4f} || TRN_ACC: {trn_acc:.3f}\", end='')\n",
    "            print(f\" || trn_blue_acc: {trn_blue_acc:.2f} || trn_oragne_acc = {trn_orange_acc:.2f}\")\n",
    "            net.partition(partition=True, title=f\"{epoch+1}\")\n",
    "print(\"saving the net ... \")\n",
    "torch.save(net.state_dict(), f\"./saved/saved_net_width_{width}_{int(trn_acc)}.pt\") \n",
    "time.sleep(1)\n",
    "print(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-burner",
   "metadata": {},
   "source": [
    "Make a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accompanied-objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "## gif maker.\n",
    "# # images to video (mp4)\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "folder_name = \"./figs\"\n",
    "img_array = []\n",
    "# alist - \n",
    "for filename in sorted(glob.glob(f'{folder_name}/*.png'), key=os.path.getmtime):\n",
    "# for filename in (glob.glob(f'{folder_name}/*.png')):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    " \n",
    " \n",
    "out = cv2.VideoWriter(f'{folder_name}/video.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 20, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n",
    "print(\"Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
